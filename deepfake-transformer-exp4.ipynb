{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\araut1\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_embedding            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">53,778,432</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1280\u001b[0m)       │     \u001b[38;5;34m5,919,312\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ positional_embedding            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1280\u001b[0m)       │        \u001b[38;5;34m38,400\u001b[0m │\n",
       "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1280\u001b[0m)       │    \u001b[38;5;34m53,778,432\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m163,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">59,900,241</span> (228.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m59,900,241\u001b[0m (228.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">59,839,633</span> (228.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m59,839,633\u001b[0m (228.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,608</span> (236.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m60,608\u001b[0m (236.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - accuracy: 0.5691 - auc: 0.5849 - loss: 0.9904 "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def load_and_preprocess_videos(video_folder, label, max_frames=30, frame_size=(224, 224)):\n",
    "    videos = []\n",
    "    labels = []\n",
    "    \n",
    "    if not os.path.exists(video_folder):\n",
    "        raise FileNotFoundError(f\"Directory not found: {video_folder}\")\n",
    "    \n",
    "    for video_file in os.listdir(video_folder):\n",
    "        video_path = os.path.join(video_folder, video_file)\n",
    "        \n",
    "        # Read video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Warning: Could not open video {video_path}\")\n",
    "            continue\n",
    "            \n",
    "        frames = []\n",
    "        frame_count = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or frame_count >= max_frames:\n",
    "                break\n",
    "                \n",
    "            # Convert BGR to RGB\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Preprocess frame\n",
    "            frame = cv2.resize(frame, frame_size)\n",
    "            frame = frame / 255.0  # Normalize\n",
    "            frames.append(frame)\n",
    "            frame_count += 1\n",
    "            \n",
    "        # Pad if video is shorter than max_frames\n",
    "        if len(frames) < max_frames:\n",
    "            padding = [np.zeros_like(frames[0]) for _ in range(max_frames - len(frames))]\n",
    "            frames.extend(padding)\n",
    "            \n",
    "        videos.append(np.array(frames))\n",
    "        labels.append(label)\n",
    "        \n",
    "        cap.release()\n",
    "    \n",
    "    return np.array(videos, dtype=np.float32), np.array(labels)\n",
    "\n",
    "# Load datasets - replace with your actual folder paths\n",
    "real_videos, real_labels = load_and_preprocess_videos('Real', 0)\n",
    "fake_videos, fake_labels = load_and_preprocess_videos('Fake', 1)\n",
    "\n",
    "# Combine datasets\n",
    "X = np.concatenate((real_videos, fake_videos), axis=0)\n",
    "y = np.concatenate((real_labels, fake_labels), axis=0)\n",
    "\n",
    "# Split into train and test sets with shuffling\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length,\n",
    "            output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.embed_dim = embed_dim\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        positions = tf.range(start=0, limit=self.sequence_length, delta=1)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return inputs + embedded_positions\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, num_heads, embed_dim, dense_dim, dropout=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embed_dim,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.dense_proj = models.Sequential([\n",
    "            layers.Dense(dense_dim, activation='relu'),\n",
    "            layers.Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.dropout_1 = layers.Dropout(dropout)\n",
    "        self.dropout_2 = layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, inputs, mask=None):\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs, attention_mask=mask\n",
    "        )\n",
    "        attention_output = self.dropout_1(attention_output)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        \n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        proj_output = self.dropout_2(proj_output)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "def create_video_transformer_model(input_shape=(30, 224, 224, 3), num_classes=1):\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # CNN backbone for spatial feature extraction (using EfficientNet)\n",
    "    cnn_backbone = tf.keras.applications.EfficientNetV2B0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape[1:],\n",
    "        pooling='avg'\n",
    "    )\n",
    "    cnn_backbone.trainable = True\n",
    "    \n",
    "    # Process each frame through CNN\n",
    "    # More efficient implementation using TimeDistributed\n",
    "    x = layers.TimeDistributed(cnn_backbone)(inputs)\n",
    "    \n",
    "    # Positional embedding\n",
    "    positional_embedding = PositionalEmbedding(\n",
    "        sequence_length=input_shape[0],\n",
    "        embed_dim=x.shape[-1]\n",
    "    )\n",
    "    x = positional_embedding(x)\n",
    "    \n",
    "    # Transformer encoder\n",
    "    x = TransformerEncoder(\n",
    "        num_heads=8,\n",
    "        embed_dim=x.shape[-1],\n",
    "        dense_dim=512,\n",
    "        dropout=0.1\n",
    "    )(x)\n",
    "    \n",
    "    # Global average pooling\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Classification head\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_video_transformer_model()\n",
    "model.summary()\n",
    "\n",
    "# Compile model with better settings\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Add callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        'best_model.h5',\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max'\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        monitor='val_accuracy'\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model with proper batch size\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=8,\n",
    "    epochs=30,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy, auc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Test AUC: {auc*100:.2f}%\")\n",
    "\n",
    "# Improved inference function\n",
    "def predict_deepfake(video_path, model, max_frames=30, frame_size=(224, 224)):\n",
    "    # Preprocess video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return \"Error: Could not open video file\"\n",
    "        \n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame_count >= max_frames:\n",
    "            break\n",
    "            \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, frame_size)\n",
    "        frame = frame / 255.0\n",
    "        frames.append(frame)\n",
    "        frame_count += 1\n",
    "        \n",
    "    cap.release()\n",
    "    \n",
    "    # Pad if needed\n",
    "    if len(frames) < max_frames:\n",
    "        padding = [np.zeros_like(frames[0]) for _ in range(max_frames - len(frames))]\n",
    "        frames.extend(padding)\n",
    "        \n",
    "    frames = np.array(frames)\n",
    "    frames = np.expand_dims(frames, axis=0)  # Add batch dimension\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(frames, verbose=0)[0][0]\n",
    "    probability = prediction * 100\n",
    "    \n",
    "    if probability > 50:\n",
    "        return f\"FAKE ({probability:.2f}% confidence)\"\n",
    "    else:\n",
    "        return f\"REAL ({100 - probability:.2f}% confidence)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f808e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\araut1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in C:\\Users\\araut1/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "c:\\Users\\araut1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\araut1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\araut1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Creating dataset...\n",
      "Initializing model...\n",
      "Total model parameters: 24,180,289\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 (Training):   0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 (Training):   7%|▋         | 1/14 [00:07<01:39,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 (Training):  14%|█▍        | 2/14 [00:14<01:29,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 (Training):  21%|██▏       | 3/14 [00:22<01:23,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 (Training):  29%|██▊       | 4/14 [00:30<01:17,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n",
      "Error detecting face: 'int' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from facenet_pytorch import MTCNN\n",
    "from einops import rearrange\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Frame extraction and face detection class\n",
    "class FaceExtractor:\n",
    "    def __init__(self, face_size=224):\n",
    "        self.face_size = face_size\n",
    "        # Initialize MTCNN for face detection\n",
    "        self.mtcnn = MTCNN(\n",
    "            image_size=face_size,\n",
    "            margin=40,\n",
    "            min_face_size=50,\n",
    "            thresholds=[0.6, 0.7, 0.7],\n",
    "            factor=0.709,\n",
    "            post_process=True,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "    def extract_faces_from_video(self, video_path, max_frames=32):\n",
    "        \"\"\"Extract faces from video frames\"\"\"\n",
    "        faces = []\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Calculate sampling rate to get evenly distributed frames\n",
    "        if frame_count <= max_frames:\n",
    "            sampling_rate = 1\n",
    "        else:\n",
    "            sampling_rate = frame_count // max_frames\n",
    "            \n",
    "        frame_indices = range(0, frame_count, sampling_rate)[:max_frames]\n",
    "        \n",
    "        for i in frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Convert BGR to RGB\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Detect face and get the cropped face and bounding box\n",
    "            try:\n",
    "                face = self.mtcnn(frame)\n",
    "                if face is not None:\n",
    "                    faces.append(face)\n",
    "            except Exception as e:\n",
    "                print(f\"Error detecting face: {e}\")\n",
    "                continue\n",
    "                \n",
    "        cap.release()\n",
    "        \n",
    "        # Ensure we have faces\n",
    "        if not faces:\n",
    "            return None\n",
    "        \n",
    "        # Stack frames - only take up to max_frames\n",
    "        face_frames = torch.stack(faces[:max_frames])\n",
    "        \n",
    "        # Pad if we have fewer frames\n",
    "        if face_frames.shape[0] < max_frames:\n",
    "            padding = torch.zeros(max_frames - face_frames.shape[0], 3, self.face_size, self.face_size)\n",
    "            face_frames = torch.cat([face_frames, padding], dim=0)\n",
    "            \n",
    "        return face_frames\n",
    "\n",
    "# Dataset class\n",
    "class DeepfakeDataset(Dataset):\n",
    "    def __init__(self, real_dir, fake_dir, max_frames=32, face_size=224, transform=None, max_videos=None):\n",
    "        self.real_videos = [os.path.join(real_dir, f) for f in os.listdir(real_dir) \n",
    "                           if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        self.fake_videos = [os.path.join(fake_dir, f) for f in os.listdir(fake_dir) \n",
    "                           if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        \n",
    "        # Limit dataset size if specified\n",
    "        if max_videos:\n",
    "            self.real_videos = self.real_videos[:max_videos]\n",
    "            self.fake_videos = self.fake_videos[:max_videos]\n",
    "            \n",
    "        self.videos = self.real_videos + self.fake_videos\n",
    "        self.labels = [0] * len(self.real_videos) + [1] * len(self.fake_videos)  # 0 for real, 1 for fake\n",
    "        \n",
    "        self.max_frames = max_frames\n",
    "        self.face_extractor = FaceExtractor(face_size)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Create a cache to store extracted faces\n",
    "        self.cache = {}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.videos[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Check if we have this video in cache\n",
    "        if video_path in self.cache:\n",
    "            faces = self.cache[video_path]\n",
    "        else:\n",
    "            faces = self.face_extractor.extract_faces_from_video(video_path, self.max_frames)\n",
    "            \n",
    "            # If no faces found, create a dummy batch\n",
    "            if faces is None:\n",
    "                faces = torch.zeros(self.max_frames, 3, 224, 224)\n",
    "                \n",
    "            # Cache the extracted faces\n",
    "            self.cache[video_path] = faces\n",
    "        \n",
    "        if self.transform:\n",
    "            # Apply transforms to each frame\n",
    "            transformed_faces = torch.stack([self.transform(face) for face in faces])\n",
    "            return transformed_faces, torch.tensor(label, dtype=torch.long)\n",
    "        else:\n",
    "            return faces, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Transformer-based model for deepfake detection\n",
    "class TransformerDeepfakeDetector(nn.Module):\n",
    "    def __init__(self, num_frames=32, hidden_dim=768, num_heads=8, num_layers=6, dropout=0.1):\n",
    "        super(TransformerDeepfakeDetector, self).__init__()\n",
    "        \n",
    "        # ResNet feature extractor (using a smaller ResNet to save VRAM)\n",
    "        self.feature_extractor = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "        # Remove the final classification layer\n",
    "        self.feature_extractor = nn.Sequential(*list(self.feature_extractor.children())[:-1])\n",
    "        \n",
    "        # Get the output dimension from the feature extractor\n",
    "        self.feature_dim = 512  # ResNet18's output dim\n",
    "        \n",
    "        # Project features to hidden dimension\n",
    "        self.projection = nn.Linear(self.feature_dim, hidden_dim)\n",
    "        \n",
    "        # Position encoding\n",
    "        self.pos_encoder = PositionalEncoding(hidden_dim, dropout)\n",
    "        \n",
    "        # Transformer encoder layers\n",
    "        encoder_layers = TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, \n",
    "                                              dim_feedforward=hidden_dim*4, dropout=dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "        self.num_frames = num_frames\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, frames, channels, height, width = x.shape\n",
    "        \n",
    "        # Process each frame with the feature extractor\n",
    "        # Reshape to process all frames at once\n",
    "        x = x.view(batch_size * frames, channels, height, width)\n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(batch_size * frames, self.feature_dim)\n",
    "        \n",
    "        # Project and reshape back to [batch, frames, hidden]\n",
    "        features = self.projection(features)\n",
    "        features = features.view(batch_size, frames, self.hidden_dim)\n",
    "        \n",
    "        # Transpose for transformer input [frames, batch, hidden]\n",
    "        features = features.transpose(0, 1)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        features = self.pos_encoder(features)\n",
    "        \n",
    "        # Pass through transformer\n",
    "        encoded = self.transformer_encoder(features)\n",
    "        \n",
    "        # Use global representation (mean of all frames)\n",
    "        encoded = encoded.mean(dim=0)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(encoded)\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "# Positional encoding for transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, lr=1e-4):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for frames, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Training)\"):\n",
    "            frames = frames.to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(frames)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pred = torch.sigmoid(outputs) >= 0.5\n",
    "            train_correct += (pred == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for frames, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Validation)\"):\n",
    "                frames = frames.to(device)\n",
    "                labels = labels.float().to(device)\n",
    "                \n",
    "                outputs = model(frames)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                pred = torch.sigmoid(outputs) >= 0.5\n",
    "                val_correct += (pred == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_deepfake_detector.pth')\n",
    "            print(\"Saved best model checkpoint.\")\n",
    "\n",
    "# Function to evaluate on test set\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for frames, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            frames = frames.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(frames)\n",
    "            pred = torch.sigmoid(outputs) >= 0.5\n",
    "            \n",
    "            test_correct += (pred == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "            \n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_acc = test_correct / test_total\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Calculate confusion matrix and other metrics\n",
    "    from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "    \n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Main function to orchestrate the training and evaluation\n",
    "def main():\n",
    "    # Parameters\n",
    "    batch_size = 4  # Smaller batch size to fit in VRAM\n",
    "    max_frames = 32\n",
    "    face_size = 224\n",
    "    max_videos_per_class = None  # Set to a number if you want to limit dataset size\n",
    "    \n",
    "    # Data augmentation and transformation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create dataset\n",
    "    print(\"Creating dataset...\")\n",
    "    dataset = DeepfakeDataset(\n",
    "        real_dir=\"Real\",\n",
    "        fake_dir=\"Fake\",\n",
    "        max_frames=max_frames,\n",
    "        face_size=face_size,\n",
    "        transform=transform,\n",
    "        max_videos=max_videos_per_class\n",
    "    )\n",
    "    \n",
    "    # Split dataset\n",
    "    dataset_size = len(dataset)\n",
    "    train_size = int(0.7 * dataset_size)\n",
    "    val_size = int(0.15 * dataset_size)\n",
    "    test_size = dataset_size - train_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size, test_size]\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"Initializing model...\")\n",
    "    model = TransformerDeepfakeDetector(\n",
    "        num_frames=max_frames,\n",
    "        hidden_dim=512,  # Reduced dimension to save VRAM\n",
    "        num_heads=8,\n",
    "        num_layers=4,    # Reduced layers to save VRAM\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total model parameters: {total_params:,}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Starting training...\")\n",
    "    train_model(model, train_loader, val_loader, num_epochs=15)\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    print(\"Loading best model for evaluation...\")\n",
    "    model.load_state_dict(torch.load('best_deepfake_detector.pth'))\n",
    "    evaluate_model(model, test_loader)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9a6f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting facenet_pytorch\n",
      "  Using cached facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy<2.0.0,>=1.24.0 (from facenet_pytorch)\n",
      "  Using cached numpy-1.26.4.tar.gz (15.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [14 lines of output]\n",
      "      + c:\\Program Files\\Python313\\python.exe C:\\Users\\araut1\\AppData\\Local\\Temp\\pip-install-p15cgjld\\numpy_0957b6ba99db41f09d52b835d29fb4c6\\vendored-meson\\meson\\meson.py setup C:\\Users\\araut1\\AppData\\Local\\Temp\\pip-install-p15cgjld\\numpy_0957b6ba99db41f09d52b835d29fb4c6 C:\\Users\\araut1\\AppData\\Local\\Temp\\pip-install-p15cgjld\\numpy_0957b6ba99db41f09d52b835d29fb4c6\\.mesonpy-_ron4h9j -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\araut1\\AppData\\Local\\Temp\\pip-install-p15cgjld\\numpy_0957b6ba99db41f09d52b835d29fb4c6\\.mesonpy-_ron4h9j\\meson-python-native-file.ini\n",
      "      The Meson build system\n",
      "      Version: 1.2.99\n",
      "      Source dir: C:\\Users\\araut1\\AppData\\Local\\Temp\\pip-install-p15cgjld\\numpy_0957b6ba99db41f09d52b835d29fb4c6\n",
      "      Build dir: C:\\Users\\araut1\\AppData\\Local\\Temp\\pip-install-p15cgjld\\numpy_0957b6ba99db41f09d52b835d29fb4c6\\.mesonpy-_ron4h9j\n",
      "      Build type: native build\n",
      "      Project name: NumPy\n",
      "      Project version: 1.26.4\n",
      "      Activating VS 17.10.5\n",
      "      The system cannot find the file specified.\n",
      "      \n",
      "      ..\\meson.build:1:0: ERROR: Compiler cl cannot compile programs.\n",
      "      \n",
      "      A full log can be found at C:\\Users\\araut1\\AppData\\Local\\Temp\\pip-install-p15cgjld\\numpy_0957b6ba99db41f09d52b835d29fb4c6\\.mesonpy-_ron4h9j\\meson-logs\\meson-log.txt\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install facenet_pytorch "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
